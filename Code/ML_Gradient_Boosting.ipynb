{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\utilizador\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\utilizador\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import math\n",
    "import csv\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier  #GBM algorithm\n",
    "from sklearn import cross_validation, metrics, preprocessing   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def import_features(filepath):\n",
    "    data = []\n",
    "    with open(filepath, 'r') as csvfile:\n",
    "        file = csv.reader(csvfile, delimiter=',')\n",
    "        for row in file:\n",
    "            line = []\n",
    "            for i in range(0, 264):\n",
    "                line.append(float(row[i]))\n",
    "            data.append(line)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def import_y(filepath):\n",
    "    return numpy.loadtxt(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def export_data_accuracy(y):\n",
    "    with open('pred_label_accuracy.csv', 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow(['Sample_id','Sample_label'])\n",
    "        for i in range(0, len(y)):\n",
    "            index = i+1\n",
    "            writer.writerow([str(index),str(y[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def export_data_log_loss(y):\n",
    "    with open('pred_label_loss.csv', 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow(['Sample_id','Class_1','Class_2','Class_3','Class_4','Class_5','Class_6','Class_7','Class_8','Class_9','Class_10'])\n",
    "        for i in range(0, len(y)):\n",
    "            index = i+1\n",
    "            temp = [str(index)]\n",
    "            for k in range(0, len(y[i])):\n",
    "                temp.append(str(y[i][k]))\n",
    "            writer.writerow(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_features(Xtrain, Xtest):\n",
    "    scaler = preprocessing.StandardScaler().fit(Xtrain)\n",
    "    Xtrain = scaler.transform(Xtrain)\n",
    "    Xtest = scaler.transform(Xtest)\n",
    "    return Xtrain, Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, x, y, test_set, performCV=True, printFeatureImportance=True, cv_folds=5):\n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(x, y)\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(test_set)\n",
    "    dtrain_predprob = alg.predict_proba(test_set)\n",
    "    \n",
    "    return dtrain_predictions, dtrain_predprob\n",
    "    \n",
    "    #Print model report:\n",
    "    #print(\"\\nModel Report\")\n",
    "    #print(\"Accuracy : %.4g\") % metrics.accuracy_score(y, dtrain_predictions)\n",
    "    #print(\"AUC Score (Train): %f\") % metrics.roc_auc_score(y, dtrain_predprob)\n",
    "    \n",
    "    #Print Feature Importance:\n",
    "    #if printFeatureImportance:\n",
    "        #feat_imp = pd.Series(alg.feature_importances_, predictors).sort_values(ascending=False)\n",
    "        #feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "        #plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = import_features('train_data.csv')\n",
    "y = import_y('train_labels.csv')\n",
    "y = [int(elem) for elem in y]\n",
    "\n",
    "test_set = import_features('test_data.csv')\n",
    "y_pred = []\n",
    "\n",
    "gbm0 = GradientBoostingClassifier(max_depth = 5, random_state=10)\n",
    "pred, prob = modelfit(gbm0, features, y, test_set)\n",
    "\n",
    "export_data_accuracy(pred)\n",
    "export_data_log_loss(prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
